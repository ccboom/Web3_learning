# Event 与 Bloom Filters 深度解析

还记得我们前面学 log 的时候提及的 event 和 Bloom Filters 吗？

今天我们将彻底把它拆开，深入学习。

---

## 第一部分：Event 到底是什么？

### 售货机的比喻

你想象一下，智能合约就是一个无人的售货机：

- 用户投币，买了一瓶可乐
- 售货机（合约）内部的可乐数量从 100 减少到了 99
- 但是作为老板（前端/dapp），晚上你过去了，检查少了一瓶，知道用户买了一瓶去了

**问题**：谁买的？什么时间买的？通通是不清楚的。

这样非常费劲，你得每天都过去检查。要是有一天很多人买了，那你更是头大，完全搞不清楚谁是谁了。

### Event 的解决方案

**event 就是为了解决这个问题而诞生的**。

在有人买的时候，event 就会打印一张票放在透明窗口上写了：

> xxxx（用户） 20xx年x月x日 几点几分 买了xxx（修改状态）

这时候，我们不管是晚上过去，还是第二天过去，都可以清楚的知道谁在什么时间买了什么东西。

### 为什么不用数组存储？

那我们为什么不干脆弄个数组，放在售货机（合约）的肚子里，那不是更方便？

你要明白 **EVM 链上的空间比黄金还贵**：

- 写一个新变量，大约需要消耗 **21000 gas**
- 写一条日志，也就消耗 **375 gas**

云泥之别！所以我们用 event，把数据放在链下，这样更便于我们进行查询。

---

## 第二部分：Event 的格式与使用

### 定义 Event

既然知道了小票，我们也得知道小票的格式是什么。

在 solidity 代码中，我们需要先定义这个 event 事件：

```solidity
// 定义一件事：有人买东西了
// 参数：谁买的，花了多少钱
event Purchase(address buyer, uint256 number);
```

### 触发 Event

OK，我们知道了小票长什么样，等人买东西的时候就会触发他。

solidity 使用 `emit` 来当作打印小票的动作：

```solidity
emit Purchase(msg.sender, amount);
```

一旦代码运行到 `emit` 这一行，售货机（合约）就会自动打印一张小票，这个小票会永久记录在区块里，这样我们过去查看的时候就能一眼看清谁买了什么东西。

---

## 第三部分：Indexed 参数（书签）

### 问题的提出

那我们知道，如果买东西的人变多了，小票也会变多。到时候比如我想找今天老张买了什么，那我会一直找一直找，把所有的小票都看过去，这样太浪费时间了，效率非常低。

### Indexed 的作用

所以我们有一个聪明的办法，给这些小票打上**索引（Indexed）**。

在 solidity 中，这个标签就是关键字 `indexed`。

这就像给一本书来贴书签：

- **没有 indexed 参数**：想要找到一行字在第几页，只能一页一页的翻动，直到找到为止
- **有 indexed 参数**：从书签上就能知道自己想要的这行字到底在不在这一页，只要看书签就够了

### 技术上的区别

| 你的代码 | 就像... | EVM 把它放在哪？ | 能直接搜索吗？ |
| :--- | :--- | :--- | :--- |
| **indexed 参数** | 标签/目录 | Topics (主题区) | ✅ 能！(比如：搜所有 from 是张三的记录) |
| **普通参数** | 正文内容 | Data (数据区) | ❌ 不能！(必须下载后自己慢慢解压看) |

### 限制

因为标签非常占特定的资源位置（Topic）槽位，所以 EVM 规定：

**每个事件最多有 4 个 indexed 参数**，其实通常只有三个能给你用，第一个位置通常被事件占领了，比如 `transfer` 就代表了这是一个转账的事件，他占领了第一个位置。

---

## 第四部分：Bloom Filter（布隆过滤器）

### 问题的提出

刚刚我们说到了，indexed 相当于打上了书签，但是以太坊上有几千万个区块。

现在我问了，张三买了什么东西？

难道我们要将整个链上的块都下载下来然后查看他们的 indexed 吗？显然是不现实的，也是极端不好用的。

### Bloom Filter 的作用

这时候就用到 bloom filter 了。

我们可以把它想象为**压缩了书本（区块）内容的外壳**。

比如：

- 当张三发生交易的时候，EVM 算了一下，压缩了一下内容写在本书的外壳上，比如 `张三 1`
- 当李二发生交易的时候，EVM 也算了一下，压缩了内容写在本书的外壳上，比如 `李二 1`

当我们要寻找张三发生的交易时：

- 我们不需要把书拿下来看上面的书签了
- 我们只需要看看书的外壳上面有没有写张三的压缩内容
- 如果写了，我们直接把书拿下来查找一下
- 如果没有，我们根本不需要把书从书架上（区块链中）拿下来

**这个机制的威力在于：它可以让你排除掉 99% 的你不需要的块。**

### 假阳性（False Positive）

所以速度就非常快了，但是又产生了一个新的问题。

你在书的外壳上看到了张三，那一定就是你要找的张三吗？

**并不能确定**，因为叫张三的人非常多，难免有重名的，你拿下来了看了一眼，不是你要找的那个张三也情有可原。

这时候你不可能去赌这个张三不是你找的那个，你必须拿下来看看，确认一下到底是不是，这种情况被称之为**假阳性（False Positive）**。

### Indexed 与 Bloom Filter 的关系

假如我们把 `from` 和 `to` 设置为了 indexed，但是 `amount` 没有设置 indexed，那么 amount 会出现在书的外壳上吗？

**答案是不会**，只有 indexed 的参数我们才会写在外壳上，普通参数只会静静的躺在区块里，什么都不干，没人下载的话，根本不知道内容是什么。

比如前端查询 `filter = { amount: 1000 }`，这种查询是做不到的。

### 为什么不能全员索引？

这么麻烦，为什么不能全员索引呢？

你知道的，每一个 indexed 参数，我们都要写到书壳上面。

书总共就那么大，你一直写一直写，写的上面的字压住了下面的字，谁还能看清下面的字呢？

结果就是你想找李四的时候，发现这可能也有李四，那里可能也有李四，因为字拼接在一起，所以被迫下载了全部的区块来看看到底有没有，之前的优化就全白做了。

**记住一句金句：如果你试图强调所有东西，那你其实什么都没有强调。**

---

## 第五部分：链下高效索引

### 方案一：直接问节点（Standard RPC）- 适合查户口

我们刚刚讲的 bloom filter 只是让节点在底层扫描时快了一些。

但是作为 DAPP 前端，如果你直接问节点：给我把过去 5 年老张的有关交易全部给我。

哪怕有 bloom filter，节点也可能回复你：超时了（Timeout）或者查询范围太大，我算不过来。

因为节点的主要任务是打包区块，不是陪你天天查历史数据的。

**这是最基础的方案**，就像你找到图书馆管理员，揪着它说帮我查一本书，它去查看 bloom filter，给你找张三的书。

**缺点**：

- 管理员很忙，估计不想搭理你（timeout）
- 每次都要重找，效率很低
- 最致命的：你没法做重复查询，比如问一下，谁是书最多的人，管理员会气炸，因为他得重新把所有的书都拿出来再数一遍

### 方案二：专业的记录员（The Indexer/The Graph）- 适合大数据

这是目前业界最标准的做法，我们需要引入一个中间人，比如 **The Graph**。

#### 工作模式

- 7 × 24 小时盯着图书馆，等有人出新书了，它立刻检查有没有 event
- 如果发现了事件，比如张三写了新书，它马上写到它自己的私人笔记本上（数据库），并且整理好格式
- 服务：比如你要查找张三所有的事件，它会从私人笔记本上找到并展示给你，甚至不需要 0.1 秒

#### 为什么需要 The Graph？

我们为什么需要 The Graph 这种中间层，思考这样的场景：

我们做了一个 NFT 项目，现在我们想在自己的网页上展示一个**前 10 名大户排行**。

这时候我们链上只有 transfer 事件，没有中间人帮我们整理数据，我们想做排行的时候需要做哪些步骤？

我们把每一条流水都找出来，然后最终统计一张资产表，再排序，看看前十名有哪些人。

不从头到尾把数据看一遍，谁都不知道有哪些人的资产是多少。

**如果让用户的前端去遍历**：

1. 用户打开了网页，下载了几百万的数据
2. CPU 狂转，疯狂计算
3. 等了 20 分钟，终于算出来了
4. 用户没等上，早跑路了

**这就是我们为什么需要一个 Indexer 作为一个中间层**：

- Indexer 服务器一直在后台默默遍历新出的每一个区块
- 每看到一个 transfer 事件，他就会立刻更新自己的数据库
- 当用户打开网页，前端直接问 Indexer，0.1 秒就可以返回数据，good。

---

## 第六部分：Bloom Filter 的底层逻辑（进阶）

### 数据结构

其实它是一个有 **2048 个并排的开关**。

在以太坊的区块头里面，`logsBloom` 实际上是一个固定长度的 2048 位的二进制数组（也就是 256 字节）。

初始状态下，这 2048 位全是 0：

```
[0, 0, 0, 0, ... (一共2048个) ..., 0]
```

### 如何从 Topic 到 Bits

当我们要把一个 indexed 参数写入这个过滤器的时候，EVM 会执行一套特定的算法：

1. **取 hash 值**：拿到 Topic 的 keccak-256 hash 值
2. **取样**：并不是把整个哈希值都存进去，而是从这个哈希值里提取 3 对特定的字节
3. **计算位置**：利用这 3 对字节，算出 3 个在 0 - 2047 之间的数字
4. **设置位**：把这三个位置值都设为 1

这下明白了吧！

---

## 总结

### 1. 为什么我们需要 Event (事件)？

**核心痛点**：智能合约（售货机）内部状态改变后，外部（前端/DApp）无法自动感知，且直接查询历史状态极其困难。

**解决方案**：使用 event 打印"小票"。

**成本优势**：

- **存储变量 (Storage)**：极贵（~21,000 gas），适合存合约逻辑必须的数据。
- **事件日志 (Logs)**：便宜（~375 gas），适合存给链下看的数据。

**动作**：使用 `emit` 关键字触发打印，数据永久记录在区块中。

### 2. indexed 关键字的作用（书签）

**定义**：给参数打上 `indexed` 标签，相当于给书贴书签。

**存储位置区别**：

- **有 indexed**：存入 Topics (主题区)，EVM 专门优化，可直接搜索（如：搜所有张三的购买记录）。
- **无 indexed**：存入 Data (数据区)，不可搜索，只能把整个日志下载下来解压查看（相当于正文内容）。

**限制**：每个事件最多 3 个用户自定义的 indexed 参数（第 1 个位置通常被事件签名的 Hash 占据）。

### 3. Bloom Filters (布隆过滤器) 的魔法（书壳）

**核心逻辑**：在下载区块（书）之前，先看区块头（书壳）上的压缩摘要。

**工作流**：

- EVM 将 indexed 的参数经过哈希计算，映射到布隆过滤器中。
- 查询时，先看过滤器。
  - 过滤器说"没有"：那绝对没有，直接跳过该区块（排除掉 99% 的无效块）。
  - 过滤器说"有"：可能有，也可能是重名（哈希碰撞/假阳性），必须下载区块进一步核实。

**重要原则**：

- 只有 indexed 的参数才会进入布隆过滤器。
- 全员索引是灾难：如果什么都索引，过滤器会被填满（全是 1），导致无法区分，失去了快速过滤的意义。

### 4. 链下数据查询的终极方案

#### 直接问节点 (Standard RPC)

- **原理**：利用 Bloom Filter 逐个查找。
- **缺点**：慢、容易超时、无法处理复杂逻辑（如"谁是前十名大户"）。

#### 中间人索引 (The Indexer / The Graph)

- **原理**：专业记录员。7x24 小时监听新区块，一旦有 Event，立刻解析并存入自己的高性能数据库。
- **优点**：前端查询时，直接问中间人，0.1 秒返回结果，支持复杂的排序、统计和聚合。

### 5. 进阶：Bloom Filter 的底层数据结构

**物理形态**：区块头中一个 2048 位 (256 字节) 的二进制数组，初始全为 0。

**写入算法**：

1. 对 Topic 进行 Keccak-256 哈希。
2. 取 3 对字节。
3. 算出 3 个位置（0-2047 之间）。
4. 将这 3 个位置的开关拨为 1。

### 一句话总结

Event 是链上省钱的通讯员，Indexed 是它的分类标签，Bloom Filter 是为了快速查找标签而设计的压缩目录，而 The Graph 则是为了应对大规模查询而雇佣的专业图书管理员。
